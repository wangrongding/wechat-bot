import { remark } from 'remark'
import stripMarkdown from 'strip-markdown'
import OpenAIApi from 'openai'
import dotenv from 'dotenv'
const env = dotenv.config().parsed // ç¯å¢ƒå‚æ•°
import fs from 'fs'
import path from 'path'

const __dirname = path.resolve()
// åˆ¤æ–­æ˜¯å¦æœ‰ .env æ–‡ä»¶, æ²¡æœ‰åˆ™æŠ¥é”™
const envPath = path.join(__dirname, '.env')
if (!fs.existsSync(envPath)) {
  console.log('âŒ è¯·å…ˆæ ¹æ®æ–‡æ¡£ï¼Œåˆ›å»ºå¹¶é…ç½®.envæ–‡ä»¶ï¼')
  process.exit(1)
}

let config = {
  apiKey: env.OPENAI_API_KEY,
  organization: '',
}
if (env.OPENAI_PROXY_URL) {
  config.baseURL = env.OPENAI_PROXY_URL
}
const openai = new OpenAIApi(config)
const chosen_model = env.OPENAI_MODEL || 'gpt-4o'

// å®šä¹‰ä¸€ä¸ª Map æ¥å­˜å‚¨ä¼šè¯ä¸Šä¸‹æ–‡
const conversationMap = new Map()

export async function getGptReply(prompt, conversationId) {
  console.log('ğŸš€ğŸš€ğŸš€ / prompt', prompt)
  
  // è·å–å½“å‰ä¼šè¯çš„ä¸Šä¸‹æ–‡æ¶ˆæ¯
  let messages = conversationMap.get(conversationId) || []

  // æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯
  messages.push({ role: 'user', content: prompt })
  
  // åªä¿ç•™æœ€è¿‘çš„ä¸¤æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ·å’ŒåŠ©æ‰‹å„ä¸€æ¡ï¼‰
  messages = messages.slice(-2)
  
  // å¦‚æœæœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯çš„æœ€å‰é¢
  if (env.OPENAI_SYSTEM_MESSAGE) {
    messages.unshift({ role: 'system', content: env.OPENAI_SYSTEM_MESSAGE })
  }

  const response = await openai.chat.completions.create({
    messages: messages,
    model: chosen_model,
  })
  console.log('ğŸš€ğŸš€ğŸš€ / reply', response.choices[0].message.content)
  
  // å°†åŠ©æ‰‹çš„å›å¤æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
  messages.push({ role: 'assistant', content: response.choices[0].message.content })
  // åªä¿ç•™æœ€è¿‘çš„ä¸¤æ¡æ¶ˆæ¯
  messages = messages.slice(-2)
  
  // æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
  conversationMap.set(conversationId, messages)
  
  return `${response.choices[0].message.content}\nVia ${chosen_model}`
}

