import fs from 'fs'
import path from 'path'
import dotenv from 'dotenv'
import OpenAI from 'openai'

const env = dotenv.config().parsed // ç¯å¢ƒå‚æ•°
// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config()
const url = env.TONGYI_URL
const api_key = env.TONGYI_API_KEY
const model_name = env.TONGYI_MODEL || 'qwen-plus'

const openai = new OpenAI({
  apiKey: api_key,
  baseURL: url,
  temperature: 0,
})

const __dirname = path.resolve()
// åˆ¤æ–­æ˜¯å¦æœ‰ .env æ–‡ä»¶, æ²¡æœ‰åˆ™æŠ¥é”™
const envPath = path.join(__dirname, '.env')
if (!fs.existsSync(envPath)) {
  console.log('âŒ è¯·å…ˆæ ¹æ®æ–‡æ¡£ï¼Œåˆ›å»ºå¹¶é…ç½® .env æ–‡ä»¶ï¼')
  process.exit(1)
}

export async function getTongyiReply(prompt) {
  const completion = await openai.chat.completions.create({
    messages: [
      {
        role: 'user',
        content: prompt + ' ,ç”¨ä¸­æ–‡å›ç­”',
      },
    ],
    model: model_name,
  })

  console.log('ğŸš€ğŸš€ğŸš€ / prompt', prompt)
  const Content = await completion.choices[0].message.content
  console.log('ğŸš€ğŸš€ğŸš€ / reply', Content)
  return `${Content}`
}
